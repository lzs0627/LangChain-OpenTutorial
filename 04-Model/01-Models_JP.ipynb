{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 様々なLLMモデルの使用\n",
    "\n",
    "- 著者: [eunhhyy](https://github.com/eunhhyy)\n",
    "- ピアレビュー: [Wooseok Jeong](https://github.com/jeong-wooseok)\n",
    "- 校正: [Chaeyoon Kim](https://github.com/chaeyoonyunakim)\n",
    "- これは [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial) の一部です\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/04-Model/01-Models.ipynb)[![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/04-Model/01-Models.ipynb)\n",
    "## 概要\n",
    "\n",
    "このチュートリアルは、AI市場における主要な```大規模言語モデル(LLM)```の包括的なガイドを提供します。\n",
    "\n",
    "### 目次\n",
    "\n",
    "- [概要](#概要)\n",
    "- [OpenAI GPTシリーズ](#openai-gptシリーズ)\n",
    "- [Meta Llamaシリーズ](#meta-llamaシリーズ)\n",
    "- [Anthropic Claudeシリーズ](#anthropic-claudeシリーズ)\n",
    "- [Google Geminiシリーズ](#google-geminiシリーズ)\n",
    "- [Mistral AIモデルシリーズ](#mistral-aiモデルシリーズ)\n",
    "- [Alibaba Qwenシリーズ](#alibaba-qwenシリーズ)\n",
    "\n",
    "\n",
    "### 参考文献\n",
    "- [OpenAIのモデル概要](https://platform.openai.com/docs/models#models-overview)\n",
    "- [Metaのモデル概要](https://www.llama.com/)\n",
    "- [Anthropicのモデル概要](https://docs.anthropic.com/en/docs/intro-to-claude)\n",
    "- [Googleのモデル概要](https://ai.google.dev/gemini-api/docs/models/gemini)\n",
    "- [Mistralのモデル概要](https://mistral.ai/technology/#models)\n",
    "- [Alibaba Cloudのモデル概要](https://mistral.ai/technology/#models)\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI - GPTシリーズ\n",
    "\n",
    "OpenAIのGPTモデルは、テキスト生成、要約、翻訳、Q&Aなどのタスク向けに設計された高度なトランスフォーマーベースの言語モデルです。主にクラウドベースのAPIとして提供され、開発者はモデルをホスティングせずに使用できます。オープンソースではありませんが、GPTは微調整機能を備えた事前学習済みモデルを提供します。\n",
    "\n",
    "### モデルバリアント\n",
    "\n",
    "1. **GPT-4oシリーズ（フラッグシップモデル）**\n",
    "   - **GPT-4o**: Turboより高速化された高信頼性モデル\n",
    "   - **GPT-4-turbo**: ビジョン、JSON、関数呼び出し機能を備えた最新モデル\n",
    "   - **GPT-4o-mini**: GPT-3.5 Turboの性能を上回るエントリーレベルモデル\n",
    "\n",
    "2. **O1シリーズ（推論スペシャリスト）**\n",
    "   - **O1**: 複雑な問題解決のための高度な推論モデル\n",
    "   - **O1-mini**: 特化したタスク向けの高速でコスト効果的なモデル\n",
    "\n",
    "3. **GPT-4oマルチメディアシリーズ（ベータ版）**\n",
    "   - **GPT-4o-realtime**: リアルタイム音声およびテキスト処理モデル\n",
    "   - **GPT-4o-audio-preview**: 音声入出力に特化したモデル\n",
    "\n",
    "### GPT-4o概要\n",
    "\n",
    "**コア機能**\n",
    "- 信頼性が向上した最先端のGPT-4モデル\n",
    "- GPT-4-turboバリアントと比較して高速処理\n",
    "- 広範な128,000トークンのコンテキストウィンドウ\n",
    "- 16,384トークンの最大出力容量\n",
    "\n",
    "**パフォーマンス**\n",
    "- 応答の信頼性と一貫性が優れている\n",
    "- 多様なタスクにわたる推論能力の強化\n",
    "- リアルタイムアプリケーション向けに最適化された速度\n",
    "- リソース利用のバランスの取れた効率性\n",
    "\n",
    "**使用例**\n",
    "- 複雑な分析と問題解決\n",
    "- 長文コンテンツの生成\n",
    "- 詳細な技術文書\n",
    "- 高度なコード生成とレビュー\n",
    "\n",
    "**技術仕様**\n",
    "- 最新のGPTアーキテクチャの最適化\n",
    "- 応答精度の向上\n",
    "- 組み込みの安全対策\n",
    "- コンテキスト保持の強化\n",
    "\n",
    "詳細については、[OpenAIの公式ドキュメント](https://platform.openai.com/docs/models#models-overview)を参照してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta - Llamaシリーズ\n",
    "\n",
    "MetaのLlama AIシリーズは、微調整、蒸留、柔軟なデプロイメントを可能にするオープンソースモデルを提供します。\n",
    "\n",
    "### モデルバリアント\n",
    "\n",
    "1. **Llama 3.1（多言語）**\n",
    "   - **8B**: モバイルおよびエッジデバイス向けの軽量で超高速モデル\n",
    "   - **405B**: 多様なユースケース向けのフラッグシップ基盤モデル\n",
    "\n",
    "2. **Llama 3.2（軽量およびマルチモーダル）**\n",
    "   - **1Bおよび3B**: デバイス上処理向けの効率的なモデル\n",
    "   - **11Bおよび90B**: 高解像度画像推論を備えたマルチモーダルモデル\n",
    "\n",
    "3. **Llama 3.3（多言語）**\n",
    "   - **70B**: パフォーマンスが向上した多言語サポート\n",
    "\n",
    "### Llama 3.3概要\n",
    "\n",
    "**安全機能**\n",
    "- 安全な応答のためのアライメント技術を組み込み\n",
    "\n",
    "**パフォーマンス**\n",
    "- より少ないリソースで大規模モデルに匹敵\n",
    "\n",
    "**効率性**\n",
    "- 一般的なGPU向けに最適化され、ハードウェア要件を削減\n",
    "\n",
    "**言語サポート**\n",
    "- 英語とスペイン語を含む8言語をサポート\n",
    "\n",
    "**トレーニング**\n",
    "- 15兆トークンで事前学習\n",
    "- 教師付き微調整(SFT)とRLHFを通じて微調整\n",
    "\n",
    "   > **教師付き微調整(SFT)**: 教師付き微調整は、ラベル付きデータで既存のAIモデルのパフォーマンスを向上させるプロセスです。例えば、モデルにテキスト要約を教えたい場合、「元のテキスト」と「要約されたテキスト」のペアをトレーニングデータとして提供します。この正解ペアでのトレーニングを通じて、モデルは特定のタスクでパフォーマンスを向上させることができます。\n",
    "   >\n",
    "   > **人間のフィードバックからの強化学習(RLHF)**: RLHFは、AIモデルが人間のフィードバックを通じてより良い応答を生成することを学ぶ方法です。AIが応答を生成すると、人間がそれらを評価し、モデルはこれらの評価に基づいて改善します。学生が教師のフィードバックを通じてスキルを向上させるように、AIは人間のフィードバックを通じてより倫理的で有用な応答を提供するように発展します。\n",
    "\n",
    "詳細については、[Metaの公式ドキュメント](https://www.llama.com/)を参照してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anthropic - Claudeシリーズ\n",
    "\n",
    "AnthropicのClaudeモデルは、多様なNLPタスク向けのクラウドベースAPIを備えた高度な言語モデルです。これらのモデルは、パフォーマンス、安全性、リアルタイム応答性のバランスを取ります。\n",
    "\n",
    "### モデルバリアント\n",
    "\n",
    "1. **Claude 3シリーズ（フラッグシップモデル）**\n",
    "   - **Claude 3 Haiku**: ほぼ瞬時の応答性\n",
    "   - **Claude 3 Sonnet**: 知能と速度のバランス\n",
    "   - **Claude 3 Opus**: 複雑なタスクに強力なパフォーマンス\n",
    "\n",
    "2. **Claude 3.5シリーズ（強化モデル）**\n",
    "   - **Claude 3.5 Haiku**: 強化されたリアルタイム応答\n",
    "   - **Claude 3.5 Sonnet**: 高度な研究と分析機能\n",
    "\n",
    "### Claude 3 Opus概要\n",
    "\n",
    "**コア機能**\n",
    "- 数学やコーディングなどの非常に複雑なタスクを処理\n",
    "- 詳細な文書処理のための広範なコンテキストウィンドウ\n",
    "\n",
    "**パフォーマンス**\n",
    "- 優れた信頼性と一貫性\n",
    "- リアルタイムアプリケーション向けに最適化\n",
    "\n",
    "**使用例**\n",
    "- 長文コンテンツの生成\n",
    "- 詳細な技術文書\n",
    "- 高度なコード生成とレビュー\n",
    "\n",
    "詳細については、[Anthropicの公式ドキュメント](https://docs.anthropic.com/en/docs/intro-to-claude)を参照してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google - Gemini\n",
    "\n",
    "GoogleのGeminiモデルは、効率性とスケーラビリティを優先し、幅広い高度なアプリケーション向けに設計されています。\n",
    "\n",
    "### モデルバリアント\n",
    "\n",
    "1. **Gemini 1.5 Flash**: 100万トークンのコンテキストウィンドウを提供\n",
    "2. **Gemini 1.5 Pro**: 200万トークンのコンテキストウィンドウを提供\n",
    "3. **Gemini 2.0 Flash（実験版）**: 速度とパフォーマンスが強化された次世代モデル\n",
    "\n",
    "### Gemini 2.0 Flash概要\n",
    "\n",
    "**コア機能**\n",
    "- リアルタイムビジョンおよびオーディオストリーミングアプリケーション用のマルチモーダルライブAPIをサポート\n",
    "- 空間理解の強化とネイティブ画像生成機能\n",
    "- 統合されたツール使用と改善されたエージェント機能\n",
    "\n",
    "**パフォーマンス**\n",
    "- 以前のモデルと比較して高速化され、パフォーマンスが向上\n",
    "\n",
    "**使用例**\n",
    "- リアルタイムストリーミングアプリケーション\n",
    "- 複雑な問題解決のための推論タスク\n",
    "- 画像とテキストの生成\n",
    "\n",
    "詳細については、[GoogleのGeminiドキュメント](https://ai.google.dev/gemini-api/docs/models/gemini)を参照してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mistral AIモデル概要\n",
    "\n",
    "Mistral AIは、多様なNLPタスク向けの商用およびオープンソースモデルを提供し、特殊なソリューションも含まれます。\n",
    "\n",
    "### モデルバリアント\n",
    "\n",
    "**商用モデル**\n",
    "- Mistral Large 24.11: 128kコンテキストウィンドウを備えた多言語モデル\n",
    "- Codestral: 80以上の言語をサポートするコーディングスペシャリスト\n",
    "- Ministralシリーズ: 低レイテンシアプリケーション向けの軽量モデル\n",
    "\n",
    "**オープンソースモデル**\n",
    "- Mathstral: 数学に焦点を当てたモデル\n",
    "- Codestral Mamba: コーディングタスク用の256kコンテキスト\n",
    "\n",
    "詳細については、[Mistralの公式ドキュメント](https://mistral.ai/technology/#models)を参照してください。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alibaba - Qwen\n",
    "\n",
    "AlibabaのQwenモデルは、多様な業界とタスク向けに最適化されたオープンソースおよび商用バリアントを提供します。\n",
    "\n",
    "### モデルバリアント\n",
    "\n",
    "1. **Qwen 2.5**: 高度な多言語モデル\n",
    "2. **Qwen-VL**: テキストと画像のマルチモーダル機能\n",
    "3. **Qwen-Audio**: オーディオ文字起こしと分析に特化\n",
    "4. **Qwen-Coder**: コーディングタスク向けに最適化\n",
    "5. **Qwen-Math**: 高度な数学問題解決用に設計\n",
    "\n",
    "### 主な機能\n",
    "\n",
    "- 様々なベンチマークで優れたパフォーマンス\n",
    "- Alibaba Cloudのプラットフォームで簡単にデプロイ\n",
    "- ライティング、画像生成、オーディオ分析などの生成AIアプリケーション\n",
    "\n",
    "詳細については、[Alibaba CloudのQwen公式ページ](https://mistral.ai/technology/#models)をご覧ください。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
